{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import scipy\n",
    "from sklearn import random_projection\n",
    "from cluster_func import em\n",
    "from cluster_func import kmeans\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "data_full = pd.read_csv('data/covtype.data.csv', header=None)\n",
    "\n",
    "#Randomly sample the data to reduce the size of dataset due to computation difficulty\n",
    "RandInd = np.random.choice(len(data_full),5000)\n",
    "data = data_full.iloc[RandInd,:].reset_index().drop(['index'], axis = 1)\n",
    "\n",
    "X = data.iloc[:,:-1].as_matrix()\n",
    "y = data.iloc[:,-1].as_matrix() - 1\n",
    "\n",
    "#Splitting data into training and testing and keeping testing data aside\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2)\n",
    "\n",
    "n_classes = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################\n",
    "#PCA\n",
    "\n",
    "print('PCA....')\n",
    "time_pca = []\n",
    "n_components_pca = range(1,55)\n",
    "cv_score_pca = []\n",
    "for comp_pca in n_components_pca:\n",
    "\t\n",
    "\t#Reducing the dimensions with optimal number of components\n",
    "\tpca_new = PCA(n_components = comp_pca)\n",
    "\tpca_new.fit(X_train)\n",
    "\tX_transformed_pca = pca_new.transform(X)\n",
    "\tnodes_hidden_layer = int((comp_pca + n_classes)/2)\n",
    "\t#neural network learner\n",
    "\tt1 = time.time()\n",
    "\tmlp = MLPClassifier(hidden_layer_sizes=(nodes_hidden_layer,),max_iter=100)\n",
    "\n",
    "\tcv_score_pca.append(np.mean(cross_val_score(mlp, X_transformed_pca, y, cv = 3)))\n",
    "\n",
    "\tt2 = time.time()\n",
    "\n",
    "\ttime_pca.append((t2 - t1))\n",
    "\n",
    "\n",
    "print('Adding cluster label and checking accuracy')\n",
    "\n",
    "#Adding a cluster label as a feature\n",
    "\n",
    "cv_score_em_pca = []\n",
    "cv_score_km_pca = []\n",
    "clf_em = GaussianMixture(n_components=n_classes,covariance_type='spherical', max_iter=100, init_params= 'kmeans')\n",
    "clf_km = KMeans(n_clusters= n_classes, init='k-means++')\n",
    "\n",
    "\n",
    "for comp_pca in n_components_pca:\n",
    "\t\n",
    "\tnodes_hidden_layer = int((comp_pca + n_classes)/2)\n",
    "\t#neural network learner\n",
    "\tmlp = MLPClassifier(hidden_layer_sizes=(nodes_hidden_layer,),max_iter=100)\n",
    "\n",
    "\t#Reducing the dimensions with optimal number of components\n",
    "\tpca_new = PCA(n_components = comp_pca)\n",
    "\tpca_new.fit(X_train)\n",
    "\tX_transformed_pca = pca_new.transform(X)\n",
    "\n",
    "\tclf_em.fit(X_transformed_pca)\n",
    "\tcluster_em = clf_em.predict(X_transformed_pca)\n",
    "\tcluster_em = np.array(cluster_em).reshape(-1,1)\n",
    "\n",
    "\tX_transformed_em_pca = np.concatenate((X_transformed_pca, cluster_em), axis=1)\n",
    "\t\n",
    "\n",
    "\tcv_score_em_pca.append(np.mean(cross_val_score(mlp, X_transformed_em_pca, y, cv = 3)))\n",
    "\n",
    "\n",
    "\tclf_km.fit(X_transformed_pca)\n",
    "\tcluster_km = clf_km.predict(X_transformed_pca)\n",
    "\tcluster_km = np.array(cluster_km).reshape(-1,1)\n",
    "\n",
    "\tX_transformed_km_pca = np.concatenate((X_transformed_pca, cluster_km), axis=1)\n",
    "\t\n",
    "\n",
    "\tcv_score_km_pca.append(np.mean(cross_val_score(mlp, X_transformed_km_pca, y, cv = 3)))\n",
    "\n",
    "\n",
    "\n",
    "#Plotting\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.plot(n_components_pca, cv_score_pca, linewidth =2)\n",
    "ax1.plot(n_components_pca, cv_score_em_pca, linewidth = 2)\n",
    "ax1.plot(n_components_pca, cv_score_km_pca, linewidth = 2)\n",
    "plt.legend(['without cluster label', 'with EM label', 'with KMeans label'])\n",
    "plt.xlabel(\"Number of components\")\n",
    "plt.ylabel(\"Three fold Cross Validation score\")\n",
    "plt.title(\"Neural network accuracy with dimensionally reduced dataset using PCA\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################\n",
    "#ICA\n",
    "\n",
    "print('ICA...')\n",
    "n_components_ica = range(1,55)\n",
    "cv_score_ica = []\n",
    "time_ica = []\n",
    "for comp_ica in n_components_ica:\n",
    "\n",
    "\t\n",
    "\t#Reducing the dimensions with optimal number of components\n",
    "\tica_new = FastICA(n_components = comp_ica)\n",
    "\tica_new.fit(X_train)\n",
    "\tX_transformed_ica = ica_new.transform(X)\n",
    "\tnodes_hidden_layer = int((comp_ica + n_classes)/2)\n",
    "\t#neural network learner\n",
    "\tt1 = time.time()\n",
    "\tmlp = MLPClassifier(hidden_layer_sizes=(nodes_hidden_layer,),max_iter=100)\n",
    "\n",
    "\tcv_score_ica.append(np.mean(cross_val_score(mlp, X_transformed_ica, y, cv = 3)))\n",
    "\n",
    "\tt2 = time.time()\n",
    "\ttime_ica.append((t2 - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding a cluster label as a feature\n",
    "\n",
    "print('Adding Cluster label and checking accuracy')\n",
    "cv_score_em_ica = []\n",
    "cv_score_km_ica = []\n",
    "clf_em = GaussianMixture(n_components=n_classes, covariance_type='spherical', max_iter=100, init_params= 'kmeans')\n",
    "clf_km = KMeans(n_clusters= n_classes, init='k-means++')\n",
    "\n",
    "\n",
    "for comp_ica in n_components_ica:\n",
    "\t\n",
    "\tnodes_hidden_layer = int((comp_ica + n_classes)/2)\n",
    "\t#neural network learner\n",
    "\tmlp = MLPClassifier(hidden_layer_sizes=(nodes_hidden_layer,),max_iter=100)\n",
    "\n",
    "\t#Reducing the dimensions with optimal number of components\n",
    "\tica_new = FastICA(n_components = comp_ica)\n",
    "\tica_new.fit(X_train)\n",
    "\tX_transformed_ica = ica_new.transform(X)\n",
    "\n",
    "\tclf_em.fit(X_transformed_ica)\n",
    "\tcluster_em = clf_em.predict(X_transformed_ica)\n",
    "\tcluster_em = np.array(cluster_em).reshape(-1,1)\n",
    "\n",
    "\tX_transformed_em_ica = np.concatenate((X_transformed_ica, cluster_em), axis=1)\n",
    "\t\n",
    "\n",
    "\tcv_score_em_ica.append(np.mean(cross_val_score(mlp, X_transformed_em_ica, y, cv = 3)))\n",
    "\n",
    "\n",
    "\tclf_km.fit(X_transformed_ica)\n",
    "\tcluster_km = clf_km.predict(X_transformed_ica)\n",
    "\tcluster_km = np.array(cluster_km).reshape(-1,1)\n",
    "\n",
    "\tX_transformed_km_ica = np.concatenate((X_transformed_ica, cluster_km), axis=1)\n",
    "\t\n",
    "\n",
    "\tcv_score_km_ica.append(np.mean(cross_val_score(mlp, X_transformed_km_ica, y, cv = 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reducing the dimensions with optimal number of components\n",
    "fig2, ax2 = plt.subplots()\n",
    "ax2.plot(n_components_ica, cv_score_ica, linewidth = 2)\n",
    "ax2.plot(n_components_ica, cv_score_em_ica, linewidth = 2)\n",
    "ax2.plot(n_components_ica, cv_score_km_ica, linewidth = 2)\n",
    "plt.legend(['without cluster label', 'with EM label', 'with Kmeans label'])\n",
    "plt.xlabel(\"Number of components\")\n",
    "plt.ylabel(\"Three fold Cross Validation score\")\n",
    "plt.title(\"Neural network accuracy with dimensionally reduced dataset using ICA\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ##########################################################################################################\n",
    "#RP\n",
    "\n",
    "\n",
    "print('RP...')\n",
    "n_components_rp = range(1,55)\n",
    "cv_score_rp = []\n",
    "\n",
    "time_rp = []\n",
    "for comp_rp in n_components_rp:\n",
    "\n",
    "\t#Reducing the dimensions with optimal number of components\n",
    "\trp_new = random_projection.GaussianRandomProjection(n_components = comp_rp)\n",
    "\trp_new.fit(X_train)\n",
    "\tX_transformed_rp = rp_new.transform(X)\n",
    "\tnodes_hidden_layer = int((comp_rp + n_classes)/2)\n",
    "\t#neural network learner\n",
    "\tt1 = time.time()\n",
    "\tmlp = MLPClassifier(hidden_layer_sizes=(nodes_hidden_layer,),max_iter=100)\n",
    "\n",
    "\tcv_score_rp.append(np.mean(cross_val_score(mlp, X_transformed_rp, y, cv = 3)))\n",
    "\n",
    "\tt2 = time.time()\n",
    "\n",
    "\ttime_rp.append((t2 - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding a cluster label as a feature\n",
    "print('Adding cluster label and checking accuracy')\n",
    "cv_score_em_rp = []\n",
    "cv_score_km_rp = []\n",
    "clf_em = GaussianMixture(n_components=n_classes, covariance_type='spherical', max_iter=100, init_params= 'kmeans')\n",
    "clf_km = KMeans(n_clusters= n_classes, init='k-means++')\n",
    "\n",
    "\n",
    "for comp_rp in n_components_rp:\n",
    "\t\n",
    "\tnodes_hidden_layer = int((comp_rp + n_classes)/2)\n",
    "\t#neural network learner\n",
    "\tmlp = MLPClassifier(hidden_layer_sizes=(nodes_hidden_layer,),max_iter=100)\n",
    "\n",
    "\t#Reducing the dimensions with optimal number of components\n",
    "\trp_new = random_projection.GaussianRandomProjection(n_components = comp_rp)\n",
    "\trp_new.fit(X_train)\n",
    "\tX_transformed_rp = rp_new.transform(X)\n",
    "\n",
    "\tclf_em.fit(X_transformed_rp)\n",
    "\tcluster_em = clf_em.predict(X_transformed_rp)\n",
    "\tcluster_em = np.array(cluster_em).reshape(-1,1)\n",
    "\n",
    "\tX_transformed_em_rp = np.concatenate((X_transformed_rp, cluster_em), axis=1)\n",
    "\t\n",
    "\n",
    "\tcv_score_em_rp.append(np.mean(cross_val_score(mlp, X_transformed_em_rp, y, cv = 3)))\n",
    "\n",
    "\n",
    "\tclf_km.fit(X_transformed_rp)\n",
    "\tcluster_km = clf_km.predict(X_transformed_rp)\n",
    "\tcluster_km = np.array(cluster_km).reshape(-1,1)\n",
    "\n",
    "\tX_transformed_km_rp = np.concatenate((X_transformed_rp, cluster_km), axis=1)\n",
    "\t\n",
    "\n",
    "\tcv_score_km_rp.append(np.mean(cross_val_score(mlp, X_transformed_km_rp, y, cv = 3)))\n",
    "\n",
    "\n",
    "fig3, ax3 = plt.subplots()\n",
    "ax3.plot(n_components_rp, cv_score_rp, linewidth= 2)\n",
    "ax3.plot(n_components_rp, cv_score_em_rp, linewidth =2)\n",
    "ax3.plot(n_components_rp, cv_score_km_rp, linewidth = 2)\n",
    "plt.legend(['without cluster label', 'with EM label', 'with Kmeans label'])\n",
    "plt.xlabel(\"Number of components\")\n",
    "plt.ylabel(\"Three fold Cross Validation score\")\n",
    "plt.title(\"Neural network accuracy with dimensionally reduced dataset using RP\")\n",
    "plt.show()\n",
    "\n",
    "# ##########################################################################################################\n",
    "#fa\n",
    "\n",
    "print('FA...')\n",
    "n_components_fa = range(1,55)\n",
    "cv_score_fa = []\n",
    "\n",
    "time_fa = []\n",
    "for comp_fa in n_components_fa:\n",
    "\n",
    "\t#Reducing the dimensions with optimal number of components\n",
    "\tfa_new = FactorAnalysis(n_components = comp_fa, max_iter = 100)\n",
    "\tfa_new.fit(X_train)\n",
    "\tX_transformed_fa = fa_new.transform(X)\n",
    "\tnodes_hidden_layer = int((comp_fa + n_classes)/2)\n",
    "\t#neural network learner\n",
    "\tt1 = time.time()\n",
    "\tmlp = MLPClassifier(hidden_layer_sizes=(nodes_hidden_layer,),max_iter=100)\n",
    "\n",
    "\tcv_score_fa.append(np.mean(cross_val_score(mlp, X_transformed_fa, y, cv = 3)))\n",
    "\n",
    "\tt2 = time.time()\n",
    "\n",
    "\ttime_fa.append((t2 - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding a cluster label as a feature\n",
    "\n",
    "print('Adding cluster label and checking accuracy.')\n",
    "cv_score_em_fa = []\n",
    "cv_score_km_fa = []\n",
    "clf_em = GaussianMixture(n_components=n_classes, covariance_type='spherical', max_iter=100, init_params= 'kmeans')\n",
    "clf_km = KMeans(n_clusters= n_classes, init='k-means++')\n",
    "\n",
    "\n",
    "for comp_fa in n_components_fa:\n",
    "\t\n",
    "\tnodes_hidden_layer = int((comp_fa + n_classes)/2)\n",
    "\t#neural network learner\n",
    "\tmlp = MLPClassifier(hidden_layer_sizes=(nodes_hidden_layer,),max_iter=100)\n",
    "\n",
    "\t#Reducing the dimensions with optimal number of components\n",
    "\tfa_new = FactorAnalysis(n_components = comp_fa, max_iter = 100)\n",
    "\tfa_new.fit(X_train)\n",
    "\tX_transformed_fa = fa_new.transform(X)\n",
    "\n",
    "\tclf_em.fit(X_transformed_fa)\n",
    "\tcluster_em = clf_em.predict(X_transformed_fa)\n",
    "\tcluster_em = np.array(cluster_em).reshape(-1,1)\n",
    "\n",
    "\tX_transformed_em_fa = np.concatenate((X_transformed_fa, cluster_em), axis=1)\n",
    "\t\n",
    "\n",
    "\tcv_score_em_fa.append(np.mean(cross_val_score(mlp, X_transformed_em_fa, y, cv = 3)))\n",
    "\n",
    "\n",
    "\tclf_km.fit(X_transformed_fa)\n",
    "\tcluster_km = clf_km.predict(X_transformed_fa)\n",
    "\tcluster_km = np.array(cluster_km).reshape(-1,1)\n",
    "\n",
    "\tX_transformed_km_fa = np.concatenate((X_transformed_fa, cluster_km), axis=1)\n",
    "\t\n",
    "\n",
    "\tcv_score_km_fa.append(np.mean(cross_val_score(mlp, X_transformed_km_fa, y, cv = 3)))\n",
    "\n",
    "\n",
    "fig4, ax4 = plt.subplots()\n",
    "ax4.plot(n_components_fa, cv_score_fa, linewidth= 2)\n",
    "ax4.plot(n_components_fa, cv_score_em_fa, linewidth =2)\n",
    "ax4.plot(n_components_fa, cv_score_km_fa, linewidth =2)\n",
    "plt.legend(['without cluster label', 'with EM label', 'with Kmeans label'])\n",
    "plt.xlabel(\"Number of components\")\n",
    "plt.ylabel(\"Three fold Cross Validation score\")\n",
    "plt.title(\"Neural network accuracy with dimensionally reduced dataset using FA\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "#Plotting neural network time\n",
    "#pca\n",
    "\n",
    "print('plotting time graph')\n",
    "fig5, ax5 = plt.subplots()\n",
    "plt.plot(n_components_pca, time_pca, linewidth =2)\n",
    "plt.plot(n_components_ica, time_ica, linewidth=2)\n",
    "plt.plot(n_components_rp, time_rp, linewidth=2)\n",
    "plt.plot(n_components_fa, time_fa, linewidth=2)\n",
    "plt.legend(['PCA', 'ICA', 'RP', 'FA'])\n",
    "plt.xlabel(\"Number of components\")\n",
    "plt.ylabel(\"Total training time for 3 fold CV\")\n",
    "plt.title(\"Neural network computation time after dimensionality reduction\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
